# Path to folder with the experiment whose results we are putting in a tidy table:
clargs <- commandArgs(trailingOnly = TRUE)
if (length(clargs) > 0) path <- clargs[1] else path <- "../data/swarm-2025-06/"


library(jsonlite)
library(tidyverse)
library(fs)



# Load server ip addresses from a designated config file, and arrange
# them in a table. The table will have three columns: `server` (whether
# we are storing the ip of Server 1, Server 2, etc.), `platform` (Arweave,
# IPFS, or Swarm), and `ip` (the actual ip address).
serversFromConfig <- function(configFile) {
  # Read JSON data from file and convert to data frame:
  fromJSON(configFile) |>
    # Convert data frame to a tibble:
    as_tibble() |>
    # Choose only the three columns pertaining to the servers:
    select(contains("dl")) |>
    # Label them as "Server 1", "Server 2", ...:
    mutate(server = str_c("Server ", 1:3), .before = 1) |>
    # Simplify column names by dropping the "_dl_servers" suffix:
    rename_with(\(x) str_remove(x, "_dl_servers"), !server) |>
    # Tidy the data:
    pivot_longer(!server, names_to = "platform", values_to = "ip") |>
    # Change storage platform names to reflect proper capitalization:
    mutate(platform = case_match(
      platform,
      "arw"   ~ "Arweave",
      "ipfs"  ~ "IPFS",
      "swarm" ~ "Swarm"
    ))
}


# Load result data of the benchmarking experiment from a JSON file,
# and arrange them in a rectangular table:
dataFromJsonRaw <- function(jsonFile) {
  # Read JSON data file:
  fromJSON(jsonFile) |>
    # Convert to a tibble:
    as_tibble() |>
    # Unpack the nested `tests` column:
    unnest(tests) |>
    # And then the sub-nested `results` column:
    unnest(results) |>
    # Give new names to some of the columns:
    rename(time_sec = download_time_seconds,
           replicate = ref,
           platform = storage)
}


# Take the raw data generated by dataFromJsonRaw(), and tidy it up:
dataFromJson <- function(rawTable, configFile) {
  # Start from the tibble generated by dataFromJsonRaw():
  rawTable |>
    # Convert the JSON true/false into R's native TRUE and FALSE:
    mutate(sha256_match = (sha256_match == "true")) |>
    # Remove unnecessary columns (note: size_kb does not actually
    # measure file size; it should be dropped):
    select(!size_kb & !server & !timestamp) |>
    # Properly capitalize IPFS in the `platform` column - important
    # for matching with the server ip data from serversFromConfig():
    mutate(platform = ifelse(platform == "Ipfs", "IPFS", platform)) |>
    # Now join table with server ip info, so we'll know which ip
    # is Server 1, which is Server 2, and so on:
    semi_join(serversFromConfig(configFile), by = join_by(platform, ip)) |>
    left_join(serversFromConfig(configFile), by = join_by(platform, ip)) |>
    # Rearrange the order of the columns and rename some of them:
    relocate(size, server, time_sec, attempts, sha256_match, .after = platform) |>
    relocate(timeout = `dl_retrieval-timeout`,
             strategy = dl_redundancy,
             erasure = ul_redundancy,
             .after = time_sec) |>
    # Give the different erasure coding levels and retrieval strategies
    # human-readable names:
    mutate(erasure = case_match(
      erasure,
      0  ~ "NONE",
      1  ~ "MEDIUM",
      2  ~ "STRONG",
      3  ~ "INSANE",
      4  ~ "PARANOID",
      NA ~ "NONE")
    ) |>
    mutate(strategy = case_match(
      strategy,
      0 ~ "NONE",
      1 ~ "DATA",
      3 ~ "RACE")
    ) |>
    # File size is a character string; convert to integer:
    mutate(size = as.integer(size)) |>
    # Indicate units in column name:
    rename(size_kb = size)
}


# Convenience function for simultaneously loading and cleaning the data:
prepareData <- function(jsonFile, configFile) {
  dataFromJson(dataFromJsonRaw(jsonFile), configFile)
}



dat <-
  tibble(file = Sys.glob(str_c(path, "results_onlyswarm*.json"))) |>
  mutate(conf = str_c(path, "config.json")) |>
  mutate(data = map2(file, conf, prepareData)) |>
  unnest(data) |>
  select(!file & !conf) |>
  select(platform, size_kb, server, erasure, strategy,
         time_sec, sha256_match, attempts)


dat |> count(sha256_match)
dat |> count(attempts)
dat |> filter(sha256_match) |> count(attempts)
dat |> count(size_kb)
dat |> count(platform)
dat |> count(server)
dat |> count(erasure)
dat |> count(strategy)
dat |> count(platform, server, size_kb, erasure, strategy) |> print(n = Inf)
dat |> filter(erasure != "NONE" & strategy == "NONE")


dat |>
  filter(sha256_match) |>
  select(platform, server, size_kb, erasure, strategy, time_sec) |>
  mutate(erasure = fct_relevel(erasure, "NONE", "MEDIUM", "STRONG",
                               "INSANE", "PARANOID")) |>
  mutate(strategy = fct_relevel(strategy, "NONE", "DATA", "RACE")) |>
  arrange(platform, server, size_kb, erasure, strategy, time_sec) |>
  count(platform, server, size_kb, erasure, strategy) |>
  print(n = Inf)


dat |>
  write_rds(str_c(path, "swarm.rds"), compress = "xz")
