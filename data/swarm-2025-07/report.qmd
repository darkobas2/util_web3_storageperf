---
title: "Comparing benchmarking experiment results from before and after Release 2.6"
author: "Gyuri Barab√°s"
format:
  pdf:
    keep-tex: false
    fontsize: 11pt
    documentclass: article
    papersize: a4paper
    margin-left: 1in
    margin-right: 1in
    margin-top: 1in
    margin-bottom: 1in
    code-block-border-left: false
    number-sections: false
  html:
    theme: cosmo
    number-sections: false
    embed-resources: true
    code-fold: true
knitr:
  opts_chunk:
    eval: true
    echo: false
    message: false
    warning: false
    fig-align: center
    tbl-cap-location: bottom
    R.options:
      knitr.kable.NA: ""
execute: 
  cache: false
editor_options: 
  chunk_output_type: console
latex-tinytex: false
---



```{r}
library(tidyverse) # Efficient data manipulation and plotting
```

The latest benchmarking was run under the same settings as the one that was run before in April. The one difference is that uploading files of 100MB or larger was not possible.^[Information from Marko Zidaric.] So instead of 100MB files, we had 50MB ones in this run of the experiment.

```{r}
readDownloadData <- function(file) {
  read_rds(file) |>
    # Remove failed downloads:
    filter(sha256_match) |>
    # Remove columns that are no longer needed:
    select(!sha256_match & !attempts) |>
    # Convert erasure and strategy to factors, for easier handling later:
    mutate(erasure = fct_relevel(erasure, "NONE", "MEDIUM", "STRONG",
                                 "INSANE", "PARANOID")) |>
    mutate(strategy = fct_relevel(strategy, "NONE", "DATA", "RACE")) |>
    # Keep rows in a logical order:
    arrange(platform, erasure, strategy, size_kb, server)
}


dat <- bind_rows(
  readDownloadData("../swarm-2025-06/swarm.rds") |>
    mutate(dataset = "2025-06", .before = 1),
  readDownloadData("../swarm-2025-07/swarm.rds") |>
    mutate(dataset = "2025-07", .before = 1)
) |>
  select(!platform)
```

We can visually compare download times across the April (2025-04) and June (2025-06, that just finished yesterday) runs. We do this both for the `DATA` (@fig-compare-data) and `RACE` (@fig-compare-race) retrieval strategies.

```{r}
#| out-width: 100%
#| fig-width: 8
#| fig-height: 9
#| fig-cap: Comparison of the April (blue, 2025-04) and June (yellow, 2025-06) benchmarking experiments, for the `DATA` retrieval strategy. Box plots are standard except no outliers are shown---that is, the thick horizontal line is the median (point that separates the top and bottom half of the data), the box around it encompasses the middle 50% of all data points, and the top/bottom whiskers show where the top/bottom 25% of the data are.
#| label: fig-compare-data


# Side-by-side visualization of the different sets of results:
compareTimePlot <- function(data, strategy) {
  data |>
    filter(strategy %in% c("NONE", {{strategy}})) |>
    ggplot(aes(x = size_kb, y = time_sec, color = dataset, fill = dataset,
               group = str_c(server, erasure, size_kb, dataset))) +
    geom_boxplot(alpha = 0.3, coef = Inf) +
    scale_x_log10(breaks = c(10, 1000, 100000),
                  labels = c("10 KB", "1 MB", "100 MB")) +
    scale_y_log10(breaks = c(0.5, 30, 1800),
                  labels = c("0.5 s", "1 m", "30 m")) +
    scale_color_manual(values = c("steelblue", "goldenrod")) +
    scale_fill_manual(values = c("steelblue", "goldenrod")) +
    labs(x = "File size", y = "Download time",
         color = "Dataset: ", fill = "Dataset: ") +
    facet_grid(erasure ~ server) +
    theme_bw() +
    theme(legend.position = "bottom")
}

compareTimePlot(dat, strategy = "DATA")
```

```{r}
#| out-width: 100%
#| fig-width: 8
#| fig-height: 9
#| fig-cap: As @fig-compare-data, but for the `RACE` retrieval strategy.
#| label: fig-compare-race


compareTimePlot(dat, strategy = "RACE")
```

The results from the two runs look quite similar, though we appear to see consistently faster download times under the `RACE` retrieval strategy for the June experiment. However, it is unlikely that this observed difference is significant. Indeed, if we make a group-by-group comparison of the two experiments (taking @fig-compare-data and @fig-compare-race, and for each file size category / retrieval strategy / erasure coding combination, compare the April and June data using a non-parametric Wilcoxon rank sum test), none of the results come out as significant at the $\alpha = 0.05$ level, after correcting for multiple comparisons (@fig-wilcox).

```{r}
#| out-width: 100%
#| fig-width: 8
#| fig-height: 9
#| fig-cap: Group-by-group comparison of results from the April (2025-04) and June (2025-06) benchmarking experiments. The y-axis shows the estimated difference (point) plus/minus 95% confidence intervals (error bars) from a Wilcoxon rank sum test applied to each distinct file size / retrieval strategy / erasure coding combination. Colors indicate whether the difference was found significant at the $\alpha = 0.05$ level, after false discovery rate correction to multiple testing. Since no results turned out as significant, everything is gray and no results are in blue.
#| label: fig-wilcox


dat |>
  mutate(ztime = (time_sec - mean(time_sec)) / sd(time_sec),
         .by = c(dataset, size_kb, server, erasure, strategy)) |>
  select(!time_sec) |>
  nest(data = dataset | server | ztime) |>
  filter(map_lgl(data, \(x) nrow(distinct(x, dataset)) == 2L)) |>
  mutate(wilcox = map(data, \(x) wilcox.test(ztime ~ dataset, data = x,
                                             conf.int = TRUE, conf.level = 0.95))) |>
  mutate(wilcox = map(wilcox, broom::tidy)) |>
  unnest(wilcox) |>
  select(!data & !statistic & !method & !alternative) |>
  mutate(adj.p.value = p.adjust(p.value, "fdr"), .after = p.value) |>
  mutate(signif = ifelse(adj.p.value < 0.05, "significant", "nonsignificant")) |>
  mutate(strategy = ifelse(strategy == "RACE", "RACE", "NONE/DATA")) |>
  mutate(size_kb = as_factor(size_kb)) |>
  ggplot(aes(x = size_kb, y = estimate, ymin = conf.low, ymax = conf.high,
             color = signif)) +
  geom_point() +
  geom_errorbar(width = 0.2) +
  scale_color_manual(values = c("significant" = "steelblue",
                                "nonsignificant" = "gray")) +
  facet_grid(erasure ~ strategy) +
  labs(x = "File size (KB)", y = "Estimated difference between April and June results",
       color = NULL) +
  theme_bw()
```

We can also check how much advantage the `RACE` strategy offers over `DATA`, for each file size category. The results are qualitatively similar for the April (@fig-erasure-box-04) as for the June (@fig-erasure-box-06) runs. The one difference is in the largest file size categories, which are difficult to compare because in April that size was 100 MB and in June 50 MB. That said, unless there is a sudden jump in behavior somewhere between those two file sizes, the June results look much better than the April ones did.

```{r}
#| out-width: 100%
#| fig-width: 8
#| fig-height: 6
#| fig-cap: Download times (y-axis) as a function of erasure level (x-axis), file size (panels), and retrieval strategy (colors). Data are only for the April (2025-04) experiment. The y-axis is individually scaled for each panel. High outliers (points more than 1.5 times the interquartile range outside the box in the upper direction) have been removed, because they otherwise distort the plots and make the corresponding results difficult to compare visually.
#| label: fig-erasure-box-04


dat |>
  filter(dataset == "2025-04") |>
  mutate(strategy = ifelse(strategy != "RACE", "NONE/DATA", "RACE")) |>
  mutate(size = case_match(size_kb, 1~"1 KB", 10~"10 KB", 100~"100 KB",
                           1000~"1 MB", 10000~"10 MB", 100000~"100 MB")) |>
  mutate(size = as_factor(size)) |>
  select(size, size_kb, strategy, server, erasure, time_sec) |>
  arrange(size, strategy, erasure, server) |>
  mutate(strategy = str_remove(strategy, "NONE/")) |>
  mutate(strategy = as_factor(ifelse(erasure == "NONE", "NONE", strategy))) |>
  mutate(size = as_factor(str_c("Size: ", size))) |>
  # Remove extreme outliers, because they otherwise distort the plot:
  filter(time_sec < 1.5 * IQR(time_sec) + quantile(time_sec, 0.75),
         .by = c(size, strategy, erasure)) |>
  ggplot(aes(x = erasure, y = time_sec, color = strategy, fill = strategy)) +
  geom_boxplot(alpha = 0.3, coef = Inf) +
  labs(color = "Strategy: ", fill = "Strategy: ", x = "Erasure level",
       y = "Download time (seconds)") +
  facet_wrap(~ size, scales = "free_y") +
  scale_color_manual(values = c("plum3", "steelblue", "goldenrod")) +
  scale_fill_manual(values = c("plum3", "steelblue", "goldenrod")) +
  theme_bw() +
  theme(legend.position = "bottom",
        axis.text.x = element_text(angle = 40, vjust = 0.75, hjust = 0.6))
```

```{r}
#| out-width: 100%
#| fig-width: 8
#| fig-height: 6
#| fig-cap: As @fig-erasure-box-04, but for the June (2025-06) experiment.
#| label: fig-erasure-box-06


dat |>
  filter(dataset == "2025-06") |>
  mutate(strategy = ifelse(strategy != "RACE", "NONE/DATA", "RACE")) |>
  mutate(size = case_match(size_kb, 1~"1 KB", 10~"10 KB", 100~"100 KB",
                           1000~"1 MB", 10000~"10 MB", 50000~"50 MB")) |>
  mutate(size = as_factor(size)) |>
  select(size, size_kb, strategy, server, erasure, time_sec) |>
  arrange(size, strategy, erasure, server) |>
  mutate(strategy = str_remove(strategy, "NONE/")) |>
  mutate(strategy = as_factor(ifelse(erasure == "NONE", "NONE", strategy))) |>
  mutate(size = as_factor(str_c("Size: ", size))) |>
  # Remove extreme outliers, because they otherwise distort the plot:
  filter(time_sec < 1.5 * IQR(time_sec) + quantile(time_sec, 0.75),
         .by = c(size, strategy, erasure)) |>
  ggplot(aes(x = erasure, y = time_sec, color = strategy, fill = strategy)) +
  geom_boxplot(alpha = 0.3, coef = Inf) +
  labs(color = "Strategy: ", fill = "Strategy: ", x = "Erasure level",
       y = "Download time (seconds)") +
  facet_wrap(~ size, scales = "free_y") +
  scale_color_manual(values = c("plum3", "steelblue", "goldenrod")) +
  scale_fill_manual(values = c("plum3", "steelblue", "goldenrod")) +
  theme_bw() +
  theme(legend.position = "bottom",
        axis.text.x = element_text(angle = 40, vjust = 0.75, hjust = 0.6))
```

When looking at upload speeds, they are nearly the same across the April and June runs, but June is slightly faster (@fig-uploads).

```{r}
uploadDataFromJsonRaw <- function(jsonFile) {
  jsonlite::fromJSON(jsonFile) |>
    (`[`)(1) |>
    as_tibble() |>
    unnest(swarm) |>
    rename(erasure = ul_redundancy, time_sec = upload_time)
}


uploadFileSizeFromJsonRaw <- function(jsonFile) {
  jsonlite::fromJSON(jsonFile) |>
    (`[`)(1) |>
    (`[[`)(1) |>
    names() |>
    (\(x) if (length(x) > 0) as.integer(x) else NA_integer_)()
}


correctedSize <- function(erasure, encryption) {
  case_when( # File size overhead from erasure coding and packed-address chunks
    (erasure == "NONE")     & (encryption == "unencrypted") ~ (128/128) * (128/127),
    (erasure == "MEDIUM")   & (encryption == "unencrypted") ~ (128/119) * (128/127),
    (erasure == "STRONG")   & (encryption == "unencrypted") ~ (128/107) * (128/127),
    (erasure == "INSANE")   & (encryption == "unencrypted") ~ (128/97)  * (128/127),
    (erasure == "PARANOID") & (encryption == "unencrypted") ~ (128/38)  * (128/127),
    (erasure == "NONE")     & (encryption == "encrypted")   ~ (64/64)   * (64/63),
    (erasure == "MEDIUM")   & (encryption == "encrypted")   ~ (64/59)   * (64/63),
    (erasure == "STRONG")   & (encryption == "encrypted")   ~ (64/53)   * (64/63),
    (erasure == "INSANE")   & (encryption == "encrypted")   ~ (64/48)   * (64/63),
    (erasure == "PARANOID") & (encryption == "encrypted")   ~ (64/19)   * (64/63)
  )
}


dataFromRefFiles <- function(dataset) {
  tibble(file = Sys.glob(str_c("../swarm-", dataset, "/references/*"))) |>
  mutate(size_kb = map_int(file, uploadFileSizeFromJsonRaw)) |>
  mutate(data = map(file, uploadDataFromJsonRaw)) |>
  unnest(data) |>
  select(erasure, size_kb, time_sec) |>
  arrange(erasure, size_kb, time_sec) |>
  mutate(erasure = as_factor(case_match(
    erasure,
    0 ~ "NONE",
    1 ~ "MEDIUM",
    2 ~ "STRONG",
    3 ~ "INSANE",
    4 ~ "PARANOID"
  )))
}


datUpload <-
  tibble(dataset = c("2025-04", "2025-06")) |>
  mutate(data = map(dataset, dataFromRefFiles)) |>
  unnest(data)
```

```{r}
#| out-width: 100%
#| fig-width: 8
#| fig-height: 5
#| fig-cap: Upload times in the April (left panel) and June (right panel) benchmarking experiments. The graphs take into account the effective sizes of the files---that is, overhead from erasure coding and packed-address chunks have been accounted for.
#| label: fig-uploads


datUpload |>
  mutate(eff_size_kb = size_kb * correctedSize(erasure, "unencrypted")) |>
  ggplot(aes(x = eff_size_kb, color = erasure, fill = erasure)) +
  geom_boxplot(aes(y = time_sec, group = str_c(erasure, eff_size_kb)),
               alpha = 0.3, width = 0.2) +
  scale_x_log10(breaks = c(10, 1000, 100000),
                labels = c("10 KB", "1 MB", "100 MB")) +
  scale_y_log10(breaks = c(0.5, 30, 1800),
                labels = c("0.5 s", "1 m", "30 m")) +
  scale_color_viridis_d(option = "C", end = 0.85) +
  scale_fill_viridis_d(option = "C", end = 0.85) +
  labs(x = "Effective file size", y = "Upload time",
       color = "Erasure coding: ", fill = "Erasure coding: ") +
  facet_grid(. ~ dataset) +
  theme_bw() +
  theme(legend.position = "bottom")
```

Since the two experiments were run under the same release version, the differences between them are caused purely by the network, and its number and distribution of nodes.
